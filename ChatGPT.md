Ниже — как **на самом деле** устроена архитектура *Primary–Replica (Master–Slave)* в PostgreSQL, и как её обычно реализуют в Kubernetes (в т.ч. с Istio). Буду говорить “primary/replica”, потому что это современная терминология.

## 0) Важная поправка про Debezium
То, что вы описали (“в журнале появилась запись → Debezium считал → перенёс изменения на другие БД”) — это **не классическая репликация PostgreSQL**.

- **Debezium** — инструмент **CDC (Change Data Capture)**, обычно читает WAL (через логическую репликацию) и публикует изменения в Kafka/другие шины, чтобы обновлять *другие системы* (поисковые индексы, витрины, кэши, микросервисы).
- Для **реплик PostgreSQL** в типичном Primary–Replica используют **physical streaming replication**: реплики получают **WAL** напрямую от primary и применяют его у себя. Это быстрее, проще и штатно.

Debezium можно использовать **параллельно** (например, для событий/интеграций), но не как “механизм поддержания реплик” в HA-кластере.

---

## 1) Что такое Primary–Replica в PostgreSQL
### Роли
- **Primary (writer)**: единственный узел, который принимает **запись** (INSERT/UPDATE/DELETE, DDL).
- **Replicas (readers)**: узлы в режиме **hot standby** — применяют WAL и могут обслуживать **SELECT** (с оговорками по консистентности/задержке).

### Что реплицируется
В классике — **физическая репликация**:
- Primary генерирует **WAL (Write-Ahead Log)** — журнал изменений страниц данных.
- Replicas “стримят” WAL и воспроизводят у себя.

Это не “пересылка SQL-запросов”, а воспроизведение низкоуровневых изменений.

---

## 2) Модули внутри PostgreSQL, которые в этом участвуют
### WAL
- Любая транзакция сначала фиксируется в WAL.
- WAL — основа и для восстановления (PITR), и для репликации.

### WAL sender / WAL receiver
- На primary работает процесс **walsender** для каждой реплики.
- На реплике работает **walreceiver**, который принимает поток WAL.

### Replication slots (слоты репликации)
- Нужны, чтобы primary **не удалял WAL**, пока реплика его не получила.
- Полезно, но опасно: “зависшая” реплика может заставить primary копить WAL и забить диск — это надо мониторить.

### Синхронная vs асинхронная репликация
- **Async (по умолчанию):** primary подтверждает commit без ожидания реплик.  
  + быстрее; − возможна потеря последних транзакций при падении primary (RPO > 0).
- **Sync:** primary подтверждает commit только после подтверждения от 1+ реплик.  
  + минимизация потерь; − возможны задержки/останов записи при проблемах реплик.

---

## 3) Кто выбирает primary и как происходит failover
Ключевой момент: **встроенный PostgreSQL не делает автоматический failover сам**. Он умеет быть primary или standby, но “выбрать лидера” и “переключиться” — задача внешнего HA-слоя.

Обычно используют один из вариантов:
- **Patroni** (очень популярно) + “хранилище консенсуса” (DCS): **etcd/Consul/ZooKeeper** или Kubernetes API
- Kubernetes-операторы (часто внутри используют Patroni):  
  **Zalando Postgres Operator**, **CrunchyData PGO**, **StackGres**, **CloudNativePG** и т.д.

### Что делает HA-слой (Patroni/Operator)
1. **Leader election / lock:** в DCS хранится “лок” — кто сейчас primary.
2. **Health-check primary:** если primary недоступен, запускается процедура failover.
3. **Выбор кандидата:** обычно выбирается реплика с самым свежим LSN (минимальная задержка).
4. **Promotion:** выбранная реплика “повышается” до primary (promotion).
5. **Fencing (крайне важно):** старый primary должен быть “обезврежен”, чтобы не писал дальше (иначе split brain).
   - В Kubernetes это часто делается удалением Pod/отключением доступа к PVC/сетевой изоляцией.
6. **Перенастройка остальных реплик:** они начинают реплицироваться уже от нового primary.
7. **Возврат старого primary:** если он ожил, его нельзя просто включить обратно как есть (данные могли разойтись). Обычно:
   - либо заново клонируют как реплику,
   - либо делают `pg_rewind` (если возможно) и переводят в standby.

### Split brain — главный враг
Если два узла одновременно считают себя primary и принимают запись — получаются **несовместимые истории данных**. Поэтому нужен:
- надежный leader-election,
- fencing,
- и правильная маршрутизация подключения клиентов.

---

## 4) Как это выглядит в Kubernetes (каждый PostgreSQL в Pod)
### Типовая “правильная” сборка
1. **PostgreSQL pods**: обычно `StatefulSet` (или то, что создаёт оператор)
   - StatefulSet даёт стабильные имена (`pg-0`, `pg-1`…) и привязку к постоянным дискам.
2. **PVC/PV**: у каждого Pod свой постоянный том (данные не должны жить внутри контейнера).
3. **Operator/Patroni**:
   - следит за состоянием,
   - делает bootstrap кластера,
   - организует репликацию,
   - делает failover/switchover,
   - обновляет Kubernetes Service/Endpoints.
4. **Service для записи (primary service)**:
   - указывает **только на текущий primary**.
5. **Service для чтения (replica service)**:
   - указывает на набор реплик (может включать primary или нет — по политике).
6. **PDB/anti-affinity/topology spread**:
   - чтобы реплики не оказались на одном узле Kubernetes,
   - и чтобы при обслуживании нод кластер не “упал весь сразу”.
7. **Мониторинг**:
   - lag репликации, заполнение WAL, состояние слотов, время failover, I/O latency, saturations.

### Где тут Istio
PostgreSQL — это **TCP**, не HTTP. Istio/Envoy умеет:
- mTLS, политики, наблюдаемость,
- TCP routing на уровне L4,

но **Istio не умеет “понять SQL”** и автоматически разделить “read vs write” по тексту запроса. Поэтому с Istio обычно делают так:
- два отдельных адреса/сервиса: `postgres-primary` и `postgres-replicas`,
- приложение само выбирает куда подключаться (или через отдельный SQL-aware proxy, см. ниже).

---

## 5) Как определяется “запрос на чтение или на запись”
Есть три распространённых подхода:

### A) На уровне приложения (самый надёжный)
Приложение/ORM знает контекст:
- запросы в рамках транзакции, “read-after-write”, блокировки — всё учитывается.
- отправляет чтение в read-service, запись в primary-service.

Минус: нужно поддерживать логику, и помнить о консистентности.

### B) Через SQL-aware proxy (read/write splitting)
Примеры: **Pgpool-II** (умеет парсить SQL и роутить SELECT на реплики).
Минусы:
- “парсинг SQL” ломается на edge cases (функции, prepared statements, COPY, временные таблицы и т.д.),
- сложнее обеспечить корректность с транзакциями (часто требуется “pinning” транзакции к одному серверу),
- появляется дополнительная точка отказа/сложность.

### C) Никакого splitting: primary обслуживает и чтение, и запись
Реплики — для HA и отдельных задач (аналитика/бэкапы).
Просто и надёжно, но чтение не разгружает primary.

---

## 6) Балансировка нагрузки
### На запись
Нужен **один адрес**, который всегда ведёт на текущий primary:
- В Kubernetes оператор обычно обновляет `Endpoints` у Service `postgres-primary`.
- Клиенты подключаются к одному DNS имени, а фактический Pod может меняться.

Важная деталь: при failover существующие подключения часто рвутся → приложение должно уметь **переподключаться**.

### На чтение
Service `postgres-replicas` балансирует TCP-соединения по репликам.
Но учтите:
- балансируется **соединение**, а не “каждый запрос” (если у вас пул соединений, нагрузка распределяется по соединениям).
- реплики могут быть с разным lag — иногда нужны политики (например, “не отправлять чтение на реплики с lag > N секунд”).

---

## 7) Как происходит репликация (пошагово)
1. Primary пишет изменения в WAL.
2. Реплика подключается к primary как replication user.
3. Реплика получает WAL потоково (streaming).
4. Реплика применяет WAL у себя.
5. Реплика в hot standby может отвечать на SELECT, но:
   - данные могут быть “чуть старее” (async),
   - некоторые запросы могут конфликтовать с vacuum/recovery (настраивается).

---

## 8) Добавление и удаление серверов PostgreSQL
### Добавить новую реплику (пустой сервер)
Обычно **вручную ничего “заливать” не нужно** — оператор/Patroni сделает bootstrap автоматически:

Что происходит логически:
1. Создаётся новый Pod + пустой PVC.
2. Он делает **base backup** (полную начальную копию) с primary или с другой реплики (в зависимости от настроек).
3. Настраивает `primary_conninfo` и начинает догонять WAL.
4. Становится готовым и попадает в read-service.

Это может быть:
- `pg_basebackup` (классика),
- или восстановление из бэкапа (например, через pgBackRest/WAL-G) — часто быстрее и разгружает primary.

### Удалить реплику
- Удаляете Pod/инстанс.
- Желательно удалить/почистить replication slot (если он был выделен именно под неё), иначе primary может копить WAL “в никуда”.

---

## 9) Что происходит если упал primary и потом “вернулся”
Корректный сценарий:
- Пока primary был недоступен, реплика стала новым primary и ушла на **новую timeline**.
- Старый primary при возвращении **не должен** продолжать работу как primary.
- Его:
  - либо пересоздают как реплику (самый безопасный и частый путь в Kubernetes),
  - либо делают `pg_rewind` и переводят в standby (если есть нужные WAL/история).

---

## 10) Kubernetes Pods vs “PostgreSQL на отдельных машинах”
### Когда PostgreSQL в Pods (Kubernetes)
**Плюсы**
- Автоматизация: bootstrap, failover, scale-out реплик, обновления (если оператор зрелый).
- Декларативность, единый способ деплоя.
- Легко раскидывать по нодам/зонам, использовать политики и наблюдаемость.

**Минусы/риски**
- Главная боль — **хранилище**: качество PV (latency/IOPS), поведение при node failure.
- “Шумные соседи”: если ноды общие, возможна деградация.
- Сложнее сеть (CNI), sidecars (Istio) могут добавлять latency/сложность для TCP.
- Нужно очень аккуратно с **fencing** и жизненным циклом томов, иначе риск split brain/порчи данных.

### Когда PostgreSQL на отдельных машинах/VM (вне Kubernetes)
**Плюсы**
- Предсказуемее I/O, проще гарантировать производительность.
- Меньше слоёв абстракции: проще отлаживать инциденты.
- Часто проще “железное” HA (SAN/локальные NVMe + отдельный HA-стек).

**Минусы**
- Автоматизация/оркестрация/масштабирование обычно сложнее и более “ручное”.
- Нужно отдельно решать: конфигурация, сервис-дискавери, обновления, мониторинг, failover orchestration.
- Интеграция с Kubernetes-приложениями (сеть/безопасность/секреты) требует дополнительной работы.

---

## 11) Что ещё важно учитывать (типовые “грабли”)
1. **Read-after-write консистентность**:  
   После записи на primary чтение с реплики может “не видеть” данные (lag). Решения:
   - читать критичные данные с primary,
   - или использовать “session consistency” (маркер LSN и ожидание догоняния реплики),
   - или sync replication (дороже).
2. **Долгие транзакции на реплике** могут мешать применению WAL (конфликты).
3. **Backups**: репликация ≠ бэкап. Нужны полноценные бэкапы + WAL archiving (PITR).
4. **Пул соединений**: pgbouncer часто ставят отдельно (но он не делает read/write routing, он про pooling).
5. **Плановые переключения (switchover)** лучше, чем аварийные (failover) — меньше риска потерь.

---

## 12) Как бы я описал “модули” целиком (карта системы)
- **PostgreSQL primary**: единственная точка записи, генерирует WAL.
- **PostgreSQL replicas**: применяют WAL, обслуживают чтение.
- **HA coordinator (Patroni/Operator)**: выбирает лидера, делает promotion/demotion, следит за здоровьем.
- **DCS (etcd/Consul/K8s API)**: хранит lock/состояние лидерства.
- **Kubernetes Services**:
  - `primary service` → текущий primary,
  - `replica service` → реплики (LB).
- **(Опционально) SQL proxy**: Pgpool-II для read/write split (если не делаете на уровне приложения).
- **Балансировщик/mesh (Istio)**: политика/безопасность/наблюдаемость на TCP, но не “понимает SQL”.
- **Backup system**: pgBackRest/WAL-G + object storage/NFS и WAL archive.
- **Monitoring/alerting**: лаг, WAL, I/O, CPU, connection count, failover events.

---

Если вы скажете:
1) какой ожидаемый SLA (RPO/RTO),  
2) нагрузка (TPS, объём данных),  
3) сколько зон/ДЦ и какие диски в Kubernetes,  
4) хотите ли read/write split или хватит primary-only для чтения,  

— я предложу 2–3 наиболее реалистичных варианта архитектуры именно “под вас” (например: CloudNativePG vs Patroni/Zalando vs Crunchy + как лучше встроить Istio, и нужен ли Pgpool-II).
