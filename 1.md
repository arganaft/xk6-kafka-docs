Использование Virtual Threads (Project Loom) — отличное решение для такого сервиса. Поскольку виртуальные потоки очень дешевы, вы можете обрабатывать тысячи одновременных запросов к API без забивания пула потоков.

Вот ответы на ваши вопросы и обновленная реализация.

1. Про FOR UPDATE SKIP LOCKED

Вас ввели в заблуждение.

FOR UPDATE: Если поток А заблокировал строку, поток Б будет ждать, пока А не завершит транзакцию (COMMIT/ROLLBACK). Это именно то, что вам нужно для генератора ID, чтобы гарантировать очередь.

SKIP LOCKED: Если поток А заблокировал строку, поток Б просто пропустит её и получит пустой результат (0 строк). Это полезно для очередей задач (чтобы несколько воркеров не хватали одну задачу), но категорически не подходит для вашей таблицы с одной строкой — сервис просто будет возвращать «ошибку», если ID в данный момент обновляется.

Резюме: Оставляйте обычный FOR UPDATE или переходите на Sequence.

2. Нативные Sequence в PostgreSQL

Sequence в Postgres работают гораздо быстрее таблиц, так как они оптимизированы для конкурентного доступа и работают вне основного механизма транзакций (не вызывают блокировок строк).

SQL для создания (64-бит, тип BIGINT в Postgres соответствует Long в Java):

SQL

CREATE SEQUENCE id_sequence AS BIGINT START WITH 1 INCREMENT BY 1 MINVALUE 1 MAXVALUE 9223372036854775807 -- Максимальный положительный Long.MAX_VALUE NO CYCLE; 

SQL для получения ID:

SQL

-- Получить один ID SELECT nextval('id_sequence'); -- Получить пачку (инкремент сразу на N) SELECT setval('id_sequence', nextval('id_sequence') + :batchSize - 1); 

Примечание: setval с nextval — это один из способов атомарно забронировать диапазон.

3. Реализация DBReader с кешированием (Hi-Lo)

Кеширование позволит вашему сервису работать невероятно быстро: вместо каждого похода в БД, вы будете брать ID из памяти, и только раз в N запросов обновлять «пачку» в базе.

Java

@Service @Slf4j public class DBReader { private final JdbcTemplate jdbcTemplate; @Value("${id-generator.cache-size:100}") // Размер пачки в памяти private int cacheSize; // Хранилище текущего диапазона в памяти private final AtomicLong currentId = new AtomicLong(0); private final AtomicLong maxIdInRange = new AtomicLong(0); @Autowired public DBReader(JdbcTemplate jdbcTemplate) { this.jdbcTemplate = jdbcTemplate; } /** * Получение одного ID (сначала из кеша, если пуст - из БД) */ @Async public CompletableFuture<Long> getNextId() { return CompletableFuture.completedFuture(incrementAndGet()); } private synchronized long incrementAndGet() { // Если кеш исчерпан, идем в БД за новой пачкой if (currentId.get() >= maxIdInRange.get()) { refillCache(); } return currentId.getAndIncrement(); } private void refillCache() { log.info("Refilling ID cache from DB..."); // Атомарно увеличиваем значение в Sequence на размер кеша // nextval возвращает начало диапазона, мы бронируем cacheSize String sql = "SELECT nextval('id_sequence')"; // В случае с Sequence, нам нужно вызвать его и "застолбить" диапазон. // Проще всего: вызвать nextval, а в приложении считать, что у нас есть диапазон на cacheSize // Но правильнее через ALTER или многократный вызов. // Однако для Sequence лучше сделать инкремент в самой БД: long startId = jdbcTemplate.queryForObject("SELECT nextval('id_sequence')", Long.class); // Если вы хотите использовать Sequence именно как генератор пачек, // лучше установить INCREMENT BY = размеру кеша (например 100). // Но так как у вас может быть много реплик приложения, // сделаем универсально: currentId.set(startId); maxIdInRange.set(startId + cacheSize); // ВАЖНО: При такой схеме Sequence в БД должен иметь INCREMENT BY равный вашему cacheSize. // Или используйте вашу старую таблицу с UPDATE ... SET last_value = last_value + :cacheSize } /** * Получение батча (напрямую из БД, чтобы не инвалидировать кеш) */ @Async @Transactional public CompletableFuture<List<Long>> getBachId(Long batchSize) { // Для батча лучше всегда ходить в БД, чтобы не путать логику кеша одного ID // Используем вашу логику с UPDATE таблицы или вызов Sequence N раз log.info("Fetching batch of size {}", batchSize); // Пример для вашей таблицы (она надежнее для разных размеров батча): String sql = "UPDATE IDSequence SET last_value = last_value + ? WHERE id_name = 'default' RETURNING last_value"; Long last = jdbcTemplate.queryForObject(sql, Long.class, batchSize); Long first = last - batchSize + 1; return CompletableFuture.completedFuture( LongStream.rangeClosed(first, last).boxed().toList() ); } } 

Почему это безопасно в многопоточности?

Virtual Threads: Ваш VirtualThreadsConfig позволяет AsyncTaskExecutor создавать новый поток на каждую задачу. Это идеально для блокирующих вызовов jdbcTemplate.

AtomicLong + synchronized: Метод incrementAndGet помечен как synchronized. В мире виртуальных потоков это безопасно (хотя стоит следить, чтобы блокировка не была слишком долгой, чтобы не «пришпилить» виртуальный поток к системному, но для AtomicLong это миллисекунды).

Гарантия уникальности: Даже если у вас 10 реплик сервиса, каждая из них пойдет в БД и «откусит» себе свой диапазон (например, Реплика 1 возьмет 1-100, Реплика 2 возьмет 101-200). Внутри себя они будут раздавать их атомарно.

Рекомендация по конфигурации

В application.properties:

Properties

id-generator.cache-size=1000 # Если используете старую таблицу, SQL будет таким: id-sequence.sql=WITH locked AS (SELECT last_value FROM IDSequence WHERE id_name = 'default' FOR UPDATE) UPDATE IDSequence SET last_value = last_value + {increment} FROM locked WHERE IDSequence.id_name = 'default' RETURNING IDSequence.last_value; 

Что изменилось в архитектуре:

Теперь запросы getId() почти мгновенные (работа с памятью).

БД не «задыхается» от транзакций при высоком RPS.

Виртуальные потоки эффективно ждут ответа от БД только при наполнении кеша.

