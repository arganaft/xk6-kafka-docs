# xk6-kafka-docs
документация для xk6-kafka
Документация по xk6-kafka для тестирования Экспертное Руководство по Использованию xk6-kafka: Нагрузочное Тестирование Apache Kafka с Помощью k6 Настоящий документ представляет собой исчерпывающее техническое руководство по использованию расширения xk6-kafka для фреймворка нагрузочного тестирования k6. Расширение разработано для симуляции высоконагруженного взаимодействия с кластерами Apache Kafka, позволяя инженерам по производительности тестировать системы, использующие Kafka в качестве основного канала передачи событий (System Under Test, SUT). Документация охватывает архитектурные особенности, жизненный цикл теста, тонкую настройку API производителя и потребителя, механизмы безопасности, обработку ошибок и анализ производительности на основе пользовательских метрик.

I. Введение, Архитектура и Развертывание xk6-kafka 1.1. Роль k6 в Экосистеме Нагрузочного Тестирования Kafka xk6-kafka является k6-расширением, разработанным на языке Go, которое предоставляет k6 возможность выступать в роли высокопроизводительного Kafka-продюсера и потребителя. Основное назначение утилиты — не просто тестирование самого Kafka-кластера, а проверка устойчивости и производительности всей распределенной системы, которая потребляет или обрабатывает события из этого кластера. Расширение позволяет автоматически генерировать сообщения, отправлять их в целевую систему через Kafka, а затем, при необходимости, потреблять их для верификации и измерения сквозной задержки.

1.2. Архитектурный Обзор Компонентов API Для взаимодействия с Kafka расширение предоставляет четыре ключевых класса, которые импортируются в сценарий k6, написанный на JavaScript:

Writer (Продюсер): Используется для создания и отправки сообщений в топик Kafka. Поддерживает батчинг, управление таймаутами и сжатие сообщений.

Reader (Потребитель): Используется для потребления сообщений из топика или группы потребителей. Предоставляет механизмы управления офсетами и таймаутами чтения.

Connection (Соединение): Предназначен для административных задач, таких как создание, перечисление и удаление топиков. Критически важен для управления ресурсами в фазах setup() и teardown().

SchemaRegistry (Реестр Схем): Используется для сериализации и десериализации данных в сложных форматах, таких как Avro и JSON Schema. Он может работать как с внешним реестром схем, так и с жестко закодированными схемами внутри скрипта.

1.3. Требования, Установка и Сборка Утилиты Для использования xk6-kafka требуется наличие установленных Go (для сборки) и k6 (для исполнения). Поскольку xk6-kafka является расширением, для его использования необходимо собрать кастомный бинарник k6.

Процесс сборки выполняется с помощью утилиты xk6 и включает в себя указание пути к расширению:

Bash xk6 build --with github.com/mostafa/xk6-kafka II. Жизненный Цикл Теста k6 и Надежное Управление Ресурсами 2.1. Инициализация Объектов (Контекст init) В соответствии с методологией k6, долгоживущие объекты, которые используются всеми виртуальными пользователями (VU) на протяжении всего теста, должны быть созданы в контексте init. Это позволяет избежать накладных расходов на их создание во время выполнения нагрузки.

Для импорта рекомендуется использовать явное указание необходимых классов и констант для повышения читаемости сценария:

JavaScript import { sleep } from "k6"; import { Writer, Reader, Connection, SchemaRegistry, SCHEMA_TYPE_STRING } from "k6/x/kafka";

// Инициализация объектов в контексте 'init' const writer = new Writer({ brokers: ["localhost:9092"], topic: "my-topic", }); const reader = new Reader({ brokers: ["localhost:9092"], topic: "my-topic", }); const connection = new Connection({ address: "localhost:9092", }); const schemaRegistry = new SchemaRegistry();

2.2. Управление Топиками и Проблема Гонки (Race Condition) Надежное управление топиками в распределенной системе является критически важным для нагрузочного тестирования.

A. Рекомендованный Метод: Использование setup() и Connection Самая распространенная причина ошибки при записи сообщений (Error writing messages) заключается в том, что топик не существует или метаданные о нем не успели распространиться по всем брокерам.

Чтобы избежать гонки, когда несколько VU пытаются взаимодействовать с топиком одновременно, создание топика должно происходить исключительно в функции setup(). Внутри setup() создается временный объект Connection, который гарантирует правильный контекст VU для административных операций:

JavaScript export function setup() { // Connection должен быть создан внутри setup() для правильного контекста const setupConnection = new Connection({ address: "localhost:9092", });

// Создание топика setupConnection.createTopic({ topic: "my-topic", numPartitions: 10, // Управление количеством партиций replicationFactor: 1, });

// Верификация и ожидание распространения метаданных const topics = setupConnection.listTopics(); if (!topics.includes("my-topic")) { throw new Error("Topic creation failed"); } setupConnection.close();

// Критически важный шаг: ожидание распространения метаданных Kafka sleep(2); }

Применение функции sleep(2) после успешного создания топика является не просто произвольной задержкой, а необходимым шагом для обеспечения эвентуальной согласованности метаданных Kafka. Это гарантирует, что когда начнется фаза default (выполнение нагрузки), объекты Writer и Reader будут видеть корректную информацию о топике и его партициях, что предотвращает сбои при инициализации продюсеров.

B. Конфигурация Создания Топика (TopicConfig) При создании топика можно указать желаемое количество партиций (numPartitions, по умолчанию 1) и коэффициент репликации (replicationFactor, по умолчанию 1).

C. Альтернативный Метод: autoCreateTopic: true Если тонкое управление количеством партиций не требуется, можно настроить Writer на автоматическое создание топика, используя настройки брокера по умолчанию:

JavaScript const writer = new Writer({ brokers: ["localhost:9092"], topic: "my-topic", autoCreateTopic: true, // Позволяет Writer создать топик });

2.3. Завершение Работы и Удаление Ресурсов (teardown()) В функции teardown() необходимо корректно закрыть все созданные соединения (Writer, Reader, Connection) для освобождения системных ресурсов и обеспечения чистого завершения теста k6. Также здесь можно выполнить удаление временного топика, если это необходимо:

JavaScript export function teardown(data) { connection.deleteTopic("my-topic"); writer.close(); reader.close(); connection.close(); }

III. API Производителя (Writer) и Оптимизация Производительности API производителя (Writer) позволяет инженеру по производительности точно настраивать поток данных для симуляции высокой пропускной способности.

3.1. Инициализация Writer и Базовая Конфигурация Минимальная конфигурация требует указания адресов брокеров и целевого топика :

JavaScript const writer = new Writer({ brokers: ["localhost:9092"], topic: "my-topic", }); 3.2. Детальная Настройка Батчинга и Надежности Для достижения максимальной пропускной способности (throughput) и контроля над задержкой необходимо настраивать параметры батчинга и подтверждений:

Настройка Батчинга: Параметры BatchSize (количество сообщений в пакете) и BatchBytes (максимальный размер пакета в байтах) позволяют балансировать между эффективностью и задержкой. Увеличение размера батча обычно повышает пропускную способность за счет меньшего количества сетевых запросов.

Подтверждения (RequiredAcks): Этот параметр регулирует надежность записи. Настройка RequiredAcks позволяет выбрать между отправкой "Fire-and-forget" (ACK=0) для максимальной скорости или требованием подтверждения от всех In-Sync Replicas (ACK=-1 или All) для обеспечения максимальной надежности.

3.3. Тонкая Настройка Таймаутов Производителя Для тестирования стабильности в реальных сетевых условиях, особенно при работе с нестабильными или облачными кластерами, критически важна возможность тонкой настройки сетевых таймаутов.

Расширение xk6-kafka предоставляет возможность настраивать три специфических таймаута на уровне WriterConfig, что подтверждается наличием соответствующих метрик (kafka_writer_batch_timeout, kafka_writer_read_timeout, kafka_writer_write_timeout) и их обработкой на транспортном уровне Go-кода. Эти параметры позволяют контролировать:

Таймаут батча (BatchTimeout): Время ожидания, пока батч заполнится.

Таймаут чтения (ReadTimeout): Таймаут на уровне TCP для операции чтения ответа от брокера.

Таймаут записи (WriteTimeout): Таймаут на уровне TCP для операции записи пакета сообщений брокеру.

Эти сетевые таймауты позволяют инженеру по производительности тестировать устойчивость к медленному или ненадежному сетевому подключению, что выходит за рамки простого контроля задержки записи.

Конвенции Времени Все конфигурации таймаутов, как для Writer, так и для Reader, должны следовать конвенциям времени Go, где время выражается в наносекундах. Для упрощения работы рекомендуется импортировать константу SECOND из модуля k6/x/kafka. Например, две секунды записываются как 2 * SECOND.

JavaScript import { SECOND, Writer } from "k6/x/kafka";

const writer = new Writer({ //... BatchTimeout: 5 * SECOND, ReadTimeout: 1 * SECOND, WriteTimeout: 1 * SECOND, }); 3.4. Управление Большими Объемами Данных: Сжатие Для эффективной симуляции высокой пропускной способности при ограничении пропускной способности сети необходимо использовать сжатие сообщений. xk6-kafka поддерживает следующие алгоритмы сжатия :

Gzip

Snappy

Lz4

Zstd

Выбор алгоритма влияет на баланс между нагрузкой на CPU клиента (k6) и брокера, а также на экономию сетевого трафика.

3.5. Структура Сообщения Расширение поддерживает отправку сообщений с ключами, что критически важно для обеспечения порядка в партициях. Также поддерживается отправка сообщений без ключа.

Для передачи метаданных, не относящихся к полезной нагрузке, xk6-kafka поддерживает заголовки (headers) на продюсируемых и потребляемых сообщениях.

IV. API Потребителя (Reader) и Управление Группами 4.1. Конфигурация ReaderConfig Базовая конфигурация Reader включает адреса брокеров и, опционально, настройки таймаута ожидания сообщений:

JavaScript const reader = new Reader({ brokers: ["localhost:9092"], topic: "my-topic", maxWait: "5s", // Максимальное время ожидания сообщений });

Параметр maxWait контролирует, как долго Reader будет ожидать появления сообщений, прежде чем сообщить о таймауте. Для тестов производительности часто устанавливается более короткий таймаут (например, 200 мс) для предотвращения зависания VU, если данных нет. В случае постоянных ошибок таймаута при потреблении, значение maxWait следует увеличить, например, до "5s".

4.2. Потребление в Режиме Группы (Consumer Group) При тестировании масштабируемых систем важно симулировать поведение реальных приложений, которые используют группы потребителей.

В архитектуре xk6-kafka существуют два режима работы Reader, которые являются взаимоисключающими:

Чтение из конкретного топика/партиции (унаследованный режим): Используется только параметр topic.

Участие в группе потребителей: Используются параметры groupID и groupTopics.

Для симуляции поведения, соответствующего реальной, масштабируемой архитектуре Kafka, необходимо использовать режим группы, где Kafka автоматически управляет распределением партиций среди потребителей, входящих в одну группу:

JavaScript import { Reader, START_OFFSETS_LAST_OFFSET } from "k6/x/kafka";

const reader = new Reader({ brokers: ["localhost:9092"], groupID: "example-group", // Уникальный ID группы groupTopics: ["example-topic"], // Топики, обслуживаемые группой startOffset: START_OFFSETS_LAST_OFFSET, });

4.3. Управление Офсетами Reader позволяет контролировать начальную точку чтения с помощью параметра startOffset. Ключевая константа START_OFFSETS_LAST_OFFSET позволяет начать чтение с самого последнего записанного офсета, игнорируя исторические данные.

Ключевые Параметры Конфигурации ReaderConfig

Параметр Тип Описание Пример/Пояснение Источник brokers string Адреса Kafka-брокеров. ["localhost:9092"] topic string Топик (для чтения без группы). "my-topic" groupID string Идентификатор группы потребителей. "example-group" groupTopics string Список топиков для группы. ["topic-1", "topic-2"] maxWait time.Duration Максимальное время ожидания сообщений. "5s" или 5 * SECOND startOffset int Начальный офсет. START_OFFSETS_LAST_OFFSET

V. Сериализация, Десериализация и Схемы Данных 5.1. Поддержка Форматов и Роль SchemaRegistry xk6-kafka поддерживает разнообразные форматы для производства и потребления сообщений, что позволяет имитировать реальные рабочие нагрузки :

String

JSON

ByteArray (для бинарных протоколов)

Avro

JSON Schema

Для работы со сложными форматами (Avro, JSON Schema) используется класс SchemaRegistry. Этот класс отвечает за согласованную сериализацию ключа и значения перед отправкой и обратную десериализацию при получении. Схемы могут быть загружены из внешнего Schema Registry или предоставлены инженером непосредственно в скрипте.

Пример использования сериализации строковых данных:

JavaScript // Сериализация writer.produce({ messages:, });

// Десериализация let deserializedValue = schemaRegistry.deserialize({ data: messages.value, schemaType: SCHEMA_TYPE_STRING, });

VI. Конфигурация Безопасности и Аутентификации 6.1. Поддерживаемые Механизмы Аутентификации Для обеспечения реалистичного тестирования в производственных средах xk6-kafka поддерживает широкий спектр механизмов аутентификации и защиты соединения :

SASL PLAIN

SASL SCRAM

SSL/TLS

AWS IAM

Поддержка загрузки файлов Java Keystore (JKS).

6.2. Интеграция Безопасности на Транспортном Уровне Параметры безопасности, такие как SASL и TLS, конфигурируются в объектах WriterConfig и ReaderConfig. На техническом уровне эти параметры передаются во внутренний компонент GetDialer, который создает защищенный транспортный объект, используемый для всех сетевых операций с брокерами.

Поскольку механизмы безопасности (например, TLS-рукопожатие и шифрование, или аутентификация SASL) интегрированы непосредственно в транспортный слой, любые накладные расходы, связанные с этими процессами, будут точно отражены в метриках задержки, экспортируемых xk6-kafka (например, kafka_writer_batch_seconds). Это позволяет инженеру измерить влияние выбранной политики безопасности на общую производительность системы.

VII. Углубленная Обработка Ошибок и Таймаутов 7.1. Распространенные Ошибки и Решения Ключевой метод предотвращения ошибок заключается в обеспечении существования и готовности топика до начала нагрузки, как было описано в разделе 2.2.

Для обработки ошибок, возникающих во время потребления, рекомендуется использовать конструкцию try-catch вокруг вызова reader.consume():

JavaScript try { let messages = reader.consume({ limit: 10, }); } catch (error) { // Обработка ошибок таймаута или соединения console.error(error); }

7.2. Использование Временных Констант (Go Time) Таймауты в Go, на котором построено расширение, измеряются в наносекундах (одна секунда равна 10 9 наносекунд). Для обеспечения читаемости и предотвращения ошибок масштабирования инженеры должны импортировать и использовать константу SECOND (или, при необходимости, MILLISECOND).

JavaScript import { SECOND } from "k6/x/kafka"; console.log(2 * SECOND); // Выводит 2000000000 (2 миллиарда наносекунд) VIII. Мониторинг Производительности: Пользовательские Метрики Kafka xk6-kafka экспортирует большое количество пользовательских метрик, позволяя инженерам точно измерять производительность и устанавливать пороговые значения (Thresholds) для ключевых показателей надежности и задержки. Эти метрики классифицируются в k6 как Counter (счетчики), Trend (тренды) и Gauge (мгновенные значения).

8.1. Анализ Метрик Производителя (Writer Metrics) Ключевые метрики производителя фокусируются на пропускной способности и надежности записи:

kafka_writer_message_count: Общее количество произведенных сообщений.

kafka_writer_batch_seconds: Trend, измеряющий время, затраченное на запись одного батча сообщений. Это основная метрика для оценки задержки записи (latency).

kafka_writer_error_count и kafka_writer_retries_count: Отслеживают количество ошибок и повторных попыток записи. Если количество повторных попыток велико, но ошибок мало, это часто указывает на временную нестабильность сети или перегрузку брокеров, которую удалось преодолеть.

8.2. Анализ Метрик Потребителя (Reader Metrics) Метрики потребителя важны для оценки эффективности обработки событий системой под тестированием.

Критически важным показателем, отражающим здоровье всей SUT, является kafka_reader_lag. Эта метрика типа Gauge отслеживает отставание (лаг) между текущим офсетом чтения потребителя и High Watermark (самым последним записанным офсетом).

Рост показателя kafka_reader_lag под нагрузкой является прямым доказательством того, что потребительское приложение не успевает обрабатывать входящий поток данных. Таким образом, лаг является главным KPI для определения узких мест в логике потребителя или в связанных с ним базах данных и сервисах.

Другие важные метрики потребителя:

kafka_reader_offset: Текущий офсет.

kafka_reader_read_seconds: Trend, время, затраченное на чтение батча сообщений.

kafka_reader_timeouts_count: Общее количество таймаутов, произошедших при чтении.

Сводка Ключевых Пользовательских Метрик

Метрика Тип Назначение Ключевой Показатель Источник kafka_writer_message_count Counter Общее количество произведенных сообщений. Объем нагрузки kafka_writer_batch_seconds Trend Время, затраченное на запись одного пакета. Задержка (Latency) kafka_writer_retries_count Counter Общее количество попыток повторной записи. Стабильность сети/брокеров kafka_reader_lag Gauge Отставание между high watermark и текущим офсетом. Отставание системы (SLO) kafka_reader_error_count Counter Общее количество ошибок при чтении/записи. Надежность

8.3. Установка Пороговых Значений (Thresholds) Интеграция пользовательских метрик Kafka позволяет инженерам устанавливать жесткие Пороговые значения (Thresholds) в конфигурации k6 для автоматической оценки успешности теста.

Примеры установки порогов:

Максимально допустимый лаг: Гарантия, что система не отстает более чем на 1000 сообщений:

JavaScript thresholds: { 'kafka_reader_lag': ['max < 1000'], } Задержка записи: Обеспечение того, что 95-й перцентиль времени записи батча не превышает 300 миллисекунд:

JavaScript thresholds: { 'kafka_writer_batch_seconds': ['p(95) < 0.3'], } Надежность: Требование нулевой частоты ошибок записи:

JavaScript thresholds: { 'kafka_writer_error_count': ['count == 0'], } IX. Комплексные Примеры Сценариев k6 Ниже представлена структурная схема полного сценария нагрузочного тестирования, объединяющего API производителя, потребителя и административные функции:

JavaScript // 1. Импорт необходимых компонентов import { sleep } from "k6"; import { Writer, Reader, Connection, SECOND, START_OFFSETS_LAST_OFFSET } from "k6/x/kafka";

// 2. Инициализация в контексте 'init' const KAFKA_BROKERS = ["localhost:9092"]; const TOPIC_NAME = "my-load-topic";

const writer = new Writer({ brokers: KAFKA_BROKERS, topic: TOPIC_NAME, BatchTimeout: 1 * SECOND, RequiredAcks: 1, // Leader acknowledgement });

const reader = new Reader({ brokers: KAFKA_BROKERS, groupID: "test-consumer-group", groupTopics:, startOffset: START_OFFSETS_LAST_OFFSET, maxWait: 500 * SECOND / 1000, // 500ms });

const adminConnection = new Connection({ address: KAFKA_BROKERS, });

// 3. Конфигурация k6 (опционально - установка порогов) export const options = { vus: 10, duration: '30s', thresholds: { 'kafka_writer_error_count': ['count == 0'], 'kafka_reader_lag': ['p(99) < 500'], // Лаг не должен превышать 500 }, };

/
